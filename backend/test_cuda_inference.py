#!/usr/bin/env python
"""
CUDAæ¨è«–ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
"""
import os
import sys
import django
from PIL import Image
import numpy as np

# Djangoè¨­å®š
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'backend.settings')
django.setup()

from inference.cuda_inference import CUDAImageClassifier, get_classifier

def create_test_image():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ç”»åƒã‚’ä½œæˆ"""
    # 224x224ã®ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒã‚’ä½œæˆ
    image_array = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
    image = Image.fromarray(image_array, 'RGB')
    return image

def test_cuda_inference():
    """CUDAæ¨è«–ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ CUDAæ¨è«–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # 1. ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ç¢ºèª
    print("\nğŸ“± ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±:")
    classifier = get_classifier('auto')
    device_info = classifier.get_device_info()
    for key, value in device_info.items():
        print(f"  {key}: {value}")
    
    # 2. å˜ä¸€ç”»åƒæ¨è«–ãƒ†ã‚¹ãƒˆ
    print("\nğŸ–¼ï¸ å˜ä¸€ç”»åƒæ¨è«–ãƒ†ã‚¹ãƒˆ:")
    test_image = create_test_image()
    result = classifier.predict(test_image)
    
    print(f"  äºˆæ¸¬ã‚¯ãƒ©ã‚¹: {result['predicted_class']}")
    print(f"  ä¿¡é ¼åº¦: {result['confidence']:.4f}")
    print(f"  å‡¦ç†æ™‚é–“: {result['processing_time']:.4f}ç§’")
    print(f"  ãƒ‡ãƒã‚¤ã‚¹: {result['device']}")
    print(f"  ã‚¯ãƒ©ã‚¹ç¢ºç‡: {result['class_probabilities']}")
    
    # 3. ãƒãƒƒãƒæ¨è«–ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“¦ ãƒãƒƒãƒæ¨è«–ãƒ†ã‚¹ãƒˆ:")
    test_images = [create_test_image() for _ in range(4)]
    batch_results = classifier.predict_batch(test_images, batch_size=2)
    
    for i, result in enumerate(batch_results):
        print(f"  ç”»åƒ{i+1}: {result['predicted_class']} (ä¿¡é ¼åº¦: {result['confidence']:.4f})")
    
    # 4. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
    print("\nâš¡ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ:")
    benchmark = classifier.benchmark(num_iterations=20)
    print(f"  ç·å‡¦ç†æ™‚é–“: {benchmark['total_time']:.4f}ç§’")
    print(f"  å¹³å‡å‡¦ç†æ™‚é–“: {benchmark['average_time_per_inference']:.4f}ç§’")
    print(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {benchmark['throughput_fps']:.2f} FPS")
    print(f"  ãƒ‡ãƒã‚¤ã‚¹: {benchmark['device']}")
    
    # 5. CPU vs CUDAæ¯”è¼ƒï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    print("\nğŸ”„ ãƒ‡ãƒã‚¤ã‚¹æ¯”è¼ƒãƒ†ã‚¹ãƒˆ:")
    
    # CPUåˆ†é¡å™¨
    cpu_classifier = CUDAImageClassifier(device_type='cpu')
    cpu_result = cpu_classifier.predict(test_image)
    print(f"  CPUå‡¦ç†æ™‚é–“: {cpu_result['processing_time']:.4f}ç§’")
    
    # CUDAåˆ†é¡å™¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    try:
        cuda_classifier = CUDAImageClassifier(device_type='cuda')
        cuda_result = cuda_classifier.predict(test_image)
        print(f"  CUDAå‡¦ç†æ™‚é–“: {cuda_result['processing_time']:.4f}ç§’")
        speedup = cpu_result['processing_time'] / cuda_result['processing_time']
        print(f"  é«˜é€ŸåŒ–å€ç‡: {speedup:.2f}x")
    except Exception as e:
        print(f"  CUDAåˆ©ç”¨ä¸å¯: {e}")
    
    print("\nâœ… CUDAæ¨è«–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")

if __name__ == "__main__":
    try:
        test_cuda_inference()
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
