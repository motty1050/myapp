#!/usr/bin/env python
"""
CUDAå¯¾å¿œç”»åƒåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ  - ç·åˆãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ
"""
import os
import sys
import django
import json
import time
from datetime import datetime

# Djangoè¨­å®š
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'backend.settings')
django.setup()

from inference.models import MLApp
from inference.cuda_inference import get_classifier

def generate_system_report():
    """ã‚·ã‚¹ãƒ†ãƒ ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    report = {
        'timestamp': datetime.now().isoformat(),
        'system_info': {},
        'database_status': {},
        'cuda_inference': {},
        'api_endpoints': {},
        'performance': {}
    }
    
    print("ğŸš€ CUDAå¯¾å¿œç”»åƒåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ  - ç·åˆãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    
    # 1. ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    print("\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:")
    classifier = get_classifier('auto')
    device_info = classifier.get_device_info()
    report['system_info'] = device_info
    
    for key, value in device_info.items():
        print(f"  {key}: {value}")
    
    # 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³
    print("\nğŸ—ƒï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³:")
    apps = MLApp.objects.all()
    report['database_status'] = {
        'total_apps': apps.count(),
        'apps': []
    }
    
    print(f"  ç·MLã‚¢ãƒ—ãƒªæ•°: {apps.count()}")
    for app in apps:
        app_info = {
            'id': app.id,
            'name': app.name,
            'app_type': app.app_type,
            'device_type': app.device_type,
            'batch_size': app.batch_size,
            'use_mixed_precision': app.use_mixed_precision,
            'is_active': app.is_active
        }
        report['database_status']['apps'].append(app_info)
        print(f"    - {app.name} (ID: {app.id}, Device: {app.device_type})")
    
    # 3. CUDAæ¨è«–ãƒ†ã‚¹ãƒˆ
    print("\nğŸ”¥ CUDAæ¨è«–ã‚·ã‚¹ãƒ†ãƒ :")
    from PIL import Image
    import numpy as np
    
    # ãƒ†ã‚¹ãƒˆç”»åƒä½œæˆ
    image_array = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
    test_image = Image.fromarray(image_array, 'RGB')
    
    # æ¨è«–ãƒ†ã‚¹ãƒˆ
    try:
        result = classifier.predict(test_image)
        report['cuda_inference'] = {
            'status': 'success',
            'predicted_class': result['predicted_class'],
            'confidence': result['confidence'],
            'processing_time': result['processing_time'],
            'device': result['device']
        }
        
        print(f"  âœ… æ¨è«–æˆåŠŸ")
        print(f"    äºˆæ¸¬ã‚¯ãƒ©ã‚¹: {result['predicted_class']}")
        print(f"    ä¿¡é ¼åº¦: {result['confidence']:.4f}")
        print(f"    å‡¦ç†æ™‚é–“: {result['processing_time']:.4f}ç§’")
        print(f"    ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {result['device']}")
        
    except Exception as e:
        report['cuda_inference'] = {
            'status': 'error',
            'error': str(e)
        }
        print(f"  âŒ æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    print("\nâš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ:")
    try:
        benchmark = classifier.benchmark(num_iterations=50)
        report['performance'] = benchmark
        
        print(f"  âœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†")
        print(f"    å¹³å‡å‡¦ç†æ™‚é–“: {benchmark['average_time_per_inference']:.4f}ç§’")
        print(f"    ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {benchmark['throughput_fps']:.2f} FPS")
        print(f"    ç·ãƒ†ã‚¹ãƒˆæ™‚é–“: {benchmark['total_time']:.4f}ç§’")
        print(f"    ãƒ†ã‚¹ãƒˆå›æ•°: {benchmark['iterations']}å›")
        
    except Exception as e:
        report['performance'] = {
            'status': 'error',
            'error': str(e)
        }
        print(f"  âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 5. API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¢ºèª
    print("\nğŸŒ APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:")
    api_endpoints = [
        'GET /api/ml-apps/ - MLã‚¢ãƒ—ãƒªä¸€è¦§å–å¾—',
        'GET /api/ml-apps/{id}/ - MLã‚¢ãƒ—ãƒªè©³ç´°å–å¾—',
        'POST /api/ml-apps/{id}/predict/ - ç”»åƒäºˆæ¸¬',
        'POST /api/ml-apps/{id}/benchmark/ - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ',
        'POST /api/ml-apps/{id}/predict_batch/ - ãƒãƒƒãƒäºˆæ¸¬',
        'GET /api/logs/ - äºˆæ¸¬ãƒ­ã‚°ä¸€è¦§'
    ]
    
    report['api_endpoints'] = {
        'available_endpoints': api_endpoints,
        'base_url': 'http://localhost:8000',
        'authentication': 'ãªã—ï¼ˆé–‹ç™ºç’°å¢ƒï¼‰'
    }
    
    for endpoint in api_endpoints:
        print(f"  âœ… {endpoint}")
    
    # 6. æ©Ÿèƒ½ã¾ã¨ã‚
    print("\nğŸ¯ å®Ÿè£…å®Œäº†æ©Ÿèƒ½:")
    features = [
        "âœ… CUDAè‡ªå‹•æ¤œå‡ºã¨CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯",
        "âœ… æ··åˆç²¾åº¦ï¼ˆFP16ï¼‰å¯¾å¿œ",
        "âœ… ãƒãƒƒãƒæ¨è«–æœ€é©åŒ–",
        "âœ… ãƒ‡ãƒã‚¤ã‚¹é–“ã®è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ",
        "âœ… Django REST APIçµ±åˆ",
        "âœ… ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†",
        "âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯",
        "âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ï¼ˆMLã‚¢ãƒ—ãƒªã€ãƒ­ã‚°ï¼‰",
        "âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°",
        "âœ… ãƒ­ã‚°è¨˜éŒ²ã‚·ã‚¹ãƒ†ãƒ "
    ]
    
    for feature in features:
        print(f"  {feature}")
    
    # 7. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
    print("\nğŸš€ æ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    next_steps = [
        "1. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆReactï¼‰ã¨ã®çµ±åˆ",
        "2. å®Ÿéš›ã®GPUç’°å¢ƒã§ã®CUDAæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ",
        "3. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’æ©Ÿèƒ½ã®å®Ÿè£…",
        "4. èªè¨¼ãƒ»èªå¯ã‚·ã‚¹ãƒ†ãƒ ã®è¿½åŠ ",
        "5. Dockerã‚³ãƒ³ãƒ†ãƒŠåŒ–",
        "6. CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰",
        "7. ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒè¨­å®š"
    ]
    
    for step in next_steps:
        print(f"  {step}")
    
    print("\n" + "=" * 60)
    print("âœ¨ CUDAå¯¾å¿œç”»åƒåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("ğŸ‰ å°ã•ãå§‹ã‚ã¦ã€ç€å®Ÿã«æ©Ÿèƒ½ã‚’æ§‹ç¯‰ã§ãã¾ã—ãŸã€‚")
    
    return report

if __name__ == "__main__":
    try:
        report = generate_system_report()
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open('system_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ system_report.json ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
    except Exception as e:
        print(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
