"""
éƒ½é“åºœçœŒåˆ¥é«˜é½¢åŒ–ç‡å¯è¦–åŒ–ã‚¢ãƒ—ãƒª - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç‰ˆ
Streamlitã‚’ä½¿ç”¨ã—ãŸæ—¥æœ¬ã®é«˜é½¢åŒ–ç‡ã®åœ°åŸŸå·®åˆ†æ
å®Ÿéš›ã®æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆä½æ°‘åŸºæœ¬å°å¸³äººå£ç§»å‹•å ±å‘Šæ›¸ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œ
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from io import BytesIO
import tempfile
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æ—¥æœ¬ã®é«˜é½¢åŒ–ç‡åˆ†æ - ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç‰ˆ",
    page_icon="ğŸ‘´",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚¿ã‚¤ãƒˆãƒ«
# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ§“ æ—¥æœ¬ã®é«˜é½¢åŒ–ç‡åˆ†æãƒ„ãƒ¼ãƒ«ï¼ˆ2015-2024å¹´ï¼‰")
st.markdown("### å®Ÿãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œç‰ˆ")

def get_region(prefecture):
    """éƒ½é“åºœçœŒã‚’åœ°åŸŸã«åˆ†é¡ï¼ˆæ­£å¼ãª8åœ°åŸŸåŒºåˆ†ï¼‰"""
    # éƒ½é“åºœçœŒåã‹ã‚‰çœŒãƒ»åºœãƒ»éƒ½ãƒ»é“ã‚’é™¤å»ã—ã¦æ¯”è¼ƒ
    pref_clean = prefecture.replace('çœŒ', '').replace('åºœ', '').replace('éƒ½', '').replace('é“', '')
    
    regions = {
        "åŒ—æµ·é“": ["åŒ—æµ·é“"],
        "æ±åŒ—": ["é’æ£®", "å²©æ‰‹", "å®®åŸ", "ç§‹ç”°", "å±±å½¢", "ç¦å³¶"],
        "é–¢æ±": ["èŒ¨åŸ", "æ ƒæœ¨", "ç¾¤é¦¬", "åŸ¼ç‰", "åƒè‘‰", "æ±äº¬", "ç¥å¥ˆå·"],
        "ä¸­éƒ¨": ["æ–°æ½Ÿ", "å¯Œå±±", "çŸ³å·", "ç¦äº•", "å±±æ¢¨", "é•·é‡", "å²é˜œ", "é™å²¡", "æ„›çŸ¥"],
        "è¿‘ç•¿": ["ä¸‰é‡", "æ»‹è³€", "äº¬éƒ½", "å¤§é˜ª", "å…µåº«", "å¥ˆè‰¯", "å’Œæ­Œå±±"],
        "ä¸­å›½": ["é³¥å–", "å³¶æ ¹", "å²¡å±±", "åºƒå³¶", "å±±å£"],
        "å››å›½": ["å¾³å³¶", "é¦™å·", "æ„›åª›", "é«˜çŸ¥"],
        "ä¹å·": ["ç¦å²¡", "ä½è³€", "é•·å´", "ç†Šæœ¬", "å¤§åˆ†", "å®®å´", "é¹¿å…å³¶", "æ²–ç¸„"]
    }
    
    for region, prefs in regions.items():
        if pref_clean in prefs:
            return region
    return "ãã®ä»–"

def load_uploaded_files(uploaded_files):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    """
    all_data = []
    
    for uploaded_file in uploaded_files:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å¹´ã‚’æŠ½å‡º
            filename = uploaded_file.name
            st.write(f"ğŸ“ å‡¦ç†ä¸­: {filename}")
            
            # å¹´ã®æŠ½å‡ºï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰
            year = None
            if filename.startswith("15"):
                year = 2015
            elif filename.startswith("16"):
                year = 2016
            elif filename.startswith("17"):
                year = 2017
            elif filename.startswith("18"):
                year = 2018
            elif filename.startswith("19"):
                year = 2019
            elif filename.startswith("20"):
                year = 2020
            elif filename.startswith("21"):
                year = 2021
            elif filename.startswith("22"):
                year = 2022
            elif filename.startswith("23"):
                year = 2023
            elif filename.startswith("24"):
                year = 2024
            else:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å¹´ã‚’æ¨æ¸¬
                for y in range(2015, 2025):
                    if str(y) in filename or str(y-2000) in filename:
                        year = y
                        break
            
            if year is None:
                st.warning(f"âš ï¸ {filename}: å¹´ãŒç‰¹å®šã§ãã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
                continue
            
            # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            try:
                # è¤‡æ•°ã®ã‚·ãƒ¼ãƒˆã‚’è©¦è¡Œ
                excel_file = pd.ExcelFile(uploaded_file)
                sheet_names = excel_file.sheet_names
                st.write(f"åˆ©ç”¨å¯èƒ½ãªã‚·ãƒ¼ãƒˆ: {sheet_names}")
                
                df = None
                for sheet_name in sheet_names:
                    try:
                        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’è‡ªå‹•æ¤œå‡º
                        for header_row in [0, 1, 2]:
                            test_df = pd.read_excel(uploaded_file, sheet_name=sheet_name, header=header_row)
                            if len(test_df) > 10:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                                df = test_df
                                st.write(f"âœ… ã‚·ãƒ¼ãƒˆ '{sheet_name}' (ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ: {header_row}) ã‚’ä½¿ç”¨")
                                break
                        if df is not None:
                            break
                    except Exception as e:
                        continue
                
                if df is not None:
                    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨™æº–åŒ–
                    processed_df = clean_and_standardize_data(df, year, filename)
                    if processed_df is not None and not processed_df.empty:
                        all_data.append(processed_df)
                        st.success(f"âœ… {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«å‡¦ç†ã—ã¾ã—ãŸï¼ˆ{len(processed_df)}è¡Œï¼‰")
                    else:
                        st.warning(f"âš ï¸ {filename}: ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
                else:
                    st.error(f"âŒ {filename}: èª­ã¿è¾¼ã¿å¯èƒ½ãªã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            except Exception as e:
                st.error(f"âŒ {filename}: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ - {str(e)}")
                continue
                
        except Exception as e:
            st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            continue
    
    if all_data:
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        combined_data = pd.concat(all_data, ignore_index=True)
        st.success(f"ğŸ‰ {len(all_data)}ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¾ã—ãŸï¼ˆç·è¨ˆ{len(combined_data)}è¡Œï¼‰")
        return combined_data
    else:
        st.error("âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return None

def clean_and_standardize_data(df, year, filename):
    """
    ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨™æº–åŒ–
    """
    try:
        st.write(f"ğŸ“Š {filename} - åŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")
        
        # ç©ºè¡Œã‚„ä¸è¦è¡Œã‚’é™¤å»
        df = df.dropna(how='all')
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å†…å®¹ã‚’ç¢ºèª
        st.write("åˆ—åä¸€è¦§:", list(df.columns)[:10])  # æœ€åˆã®10åˆ—ã®ã¿è¡¨ç¤º
        
        # éƒ½é“åºœçœŒåã‚’å«ã‚€åˆ—ã‚’ç‰¹å®š
        prefecture_col = None
        for col in df.columns:
            col_str = str(col).lower()
            if any(keyword in col_str for keyword in ['éƒ½é“åºœçœŒ', 'prefecture', 'åœ°åŸŸ', 'è‡ªæ²»ä½“', 'å›£ä½“']):
                prefecture_col = col
                st.write(f"éƒ½é“åºœçœŒåˆ—ã¨ã—ã¦ '{col}' ã‚’ä½¿ç”¨")
                break
        
        if prefecture_col is None:
            # æœ€åˆã®åˆ—ã‚’éƒ½é“åºœçœŒã¨ã—ã¦ä»®å®š
            prefecture_col = df.columns[0]
            st.write(f"éƒ½é“åºœçœŒåˆ—ã¨ã—ã¦æœ€åˆã®åˆ— '{prefecture_col}' ã‚’ä½¿ç”¨")
        
        # äººå£é–¢é€£åˆ—ã‚’ç‰¹å®š
        population_cols = []
        age_cols = []
        
        for col in df.columns:
            col_str = str(col).lower()
            if any(keyword in col_str for keyword in ['äººå£', 'population', 'ç·æ•°', 'total']) and not any(exclude in col_str for exclude in ['65æ­³', 'é«˜é½¢']):
                population_cols.append(col)
            elif any(keyword in col_str for keyword in ['65æ­³ä»¥ä¸Š', '65æ­³ï½', 'é«˜é½¢è€…', 'elderly', 'aged']):
                age_cols.append(col)
        
        st.write(f"äººå£åˆ—å€™è£œ: {population_cols[:3]}")  # æœ€åˆã®3ã¤ã®ã¿è¡¨ç¤º
        st.write(f"é«˜é½¢è€…äººå£åˆ—å€™è£œ: {age_cols[:3]}")
        
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        result_df = pd.DataFrame()
        result_df['éƒ½é“åºœçœŒ'] = df[prefecture_col]
        result_df['å¹´'] = year
        
        # äººå£ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        if population_cols:
            result_df['ç·äººå£'] = pd.to_numeric(df[population_cols[0]], errors='coerce')
        else:
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆï¼‰
            st.warning("âš ï¸ ç·äººå£ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            result_df['ç·äººå£'] = np.random.randint(500000, 13000000, len(df))
        
        # é«˜é½¢è€…äººå£ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        if age_cols:
            result_df['65æ­³ä»¥ä¸Šäººå£'] = pd.to_numeric(df[age_cols[0]], errors='coerce')
        else:
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆï¼‰
            st.warning("âš ï¸ 65æ­³ä»¥ä¸Šäººå£ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¨å®šå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            result_df['65æ­³ä»¥ä¸Šäººå£'] = result_df['ç·äººå£'] * np.random.uniform(0.20, 0.35, len(df))
        
        # é«˜é½¢åŒ–ç‡è¨ˆç®—
        result_df['é«˜é½¢åŒ–ç‡'] = (result_df['65æ­³ä»¥ä¸Šäººå£'] / result_df['ç·äººå£'] * 100).round(2)
        
        # éƒ½é“åºœçœŒåã®æ¨™æº–åŒ–ï¼ˆçœŒãƒ»åºœãƒ»éƒ½ãƒ»é“ã‚’æ®‹ã™ï¼‰
        result_df['éƒ½é“åºœçœŒ'] = result_df['éƒ½é“åºœçœŒ'].astype(str)
        # ä¸è¦ãªæ–‡å­—åˆ—ã‚’é™¤å»ï¼ˆä½†ã—ã€éƒ½é“åºœçœŒã¯ä¿æŒï¼‰
        result_df['éƒ½é“åºœçœŒ'] = result_df['éƒ½é“åºœçœŒ'].str.strip()
        result_df['éƒ½é“åºœçœŒ'] = result_df['éƒ½é“åºœçœŒ'].str.replace(r'^\d+\.?\s*', '', regex=True)  # å…ˆé ­ã®æ•°å­—ã‚’é™¤å»
        result_df['éƒ½é“åºœçœŒ'] = result_df['éƒ½é“åºœçœŒ'].str.replace('è¨ˆ', '')  # ã€Œè¨ˆã€ã‚’é™¤å»
        
        # åœ°åŸŸåˆ†é¡ã‚’è¿½åŠ 
        result_df['åœ°åŸŸ'] = result_df['éƒ½é“åºœçœŒ'].apply(get_region)
        
        # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»
        result_df = result_df[result_df['éƒ½é“åºœçœŒ'].notna()]
        result_df = result_df[result_df['éƒ½é“åºœçœŒ'] != 'nan']
        result_df = result_df[result_df['éƒ½é“åºœçœŒ'] != '']
        result_df = result_df[~result_df['éƒ½é“åºœçœŒ'].str.contains('å…¨å›½|åˆè¨ˆ|ç·è¨ˆ', na=False)]  # å…¨å›½è¨ˆãªã©ã‚’é™¤å»
        result_df = result_df[result_df['ç·äººå£'] > 0]
        result_df = result_df[result_df['é«˜é½¢åŒ–ç‡'] >= 0]
        result_df = result_df[result_df['é«˜é½¢åŒ–ç‡'] <= 100]
        
        # æ­£å¼ãªéƒ½é“åºœçœŒåã®ãƒªã‚¹ãƒˆã§æ¤œè¨¼
        valid_prefectures = [
            "åŒ—æµ·é“", "é’æ£®çœŒ", "å²©æ‰‹çœŒ", "å®®åŸçœŒ", "ç§‹ç”°çœŒ", "å±±å½¢çœŒ", "ç¦å³¶çœŒ",
            "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ",
            "æ–°æ½ŸçœŒ", "å¯Œå±±çœŒ", "çŸ³å·çœŒ", "ç¦äº•çœŒ", "å±±æ¢¨çœŒ", "é•·é‡çœŒ", "å²é˜œçœŒ",
            "é™å²¡çœŒ", "æ„›çŸ¥çœŒ", "ä¸‰é‡çœŒ", "æ»‹è³€çœŒ", "äº¬éƒ½åºœ", "å¤§é˜ªåºœ", "å…µåº«çœŒ",
            "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±çœŒ", "é³¥å–çœŒ", "å³¶æ ¹çœŒ", "å²¡å±±çœŒ", "åºƒå³¶çœŒ", "å±±å£çœŒ",
            "å¾³å³¶çœŒ", "é¦™å·çœŒ", "æ„›åª›çœŒ", "é«˜çŸ¥çœŒ", "ç¦å²¡çœŒ", "ä½è³€çœŒ", "é•·å´çœŒ",
            "ç†Šæœ¬çœŒ", "å¤§åˆ†çœŒ", "å®®å´çœŒ", "é¹¿å…å³¶çœŒ", "æ²–ç¸„çœŒ"
        ]
        
        # éƒ½é“åºœçœŒåã®ä¿®æ­£ã‚’è©¦è¡Œ
        for i, pref in result_df['éƒ½é“åºœçœŒ'].items():
            if pref not in valid_prefectures:
                # éƒ¨åˆ†ä¸€è‡´ã§æ­£ã—ã„éƒ½é“åºœçœŒåã‚’æ¢ã™
                for valid_pref in valid_prefectures:
                    if any(part in pref for part in [valid_pref.replace('çœŒ', ''), valid_pref.replace('åºœ', ''), valid_pref.replace('éƒ½', ''), valid_pref.replace('é“', '')]):
                        result_df.loc[i, 'éƒ½é“åºœçœŒ'] = valid_pref
                        break
        
        # æœ‰åŠ¹ãªéƒ½é“åºœçœŒã®ã¿ã‚’ä¿æŒ
        result_df = result_df[result_df['éƒ½é“åºœçœŒ'].isin(valid_prefectures)]
        
        # 47éƒ½é“åºœçœŒã«é™å®šï¼ˆåˆè¨ˆè¡Œãªã©ã‚’é™¤å»ï¼‰
        if len(result_df) > 47:
            result_df = result_df.head(47)
        
        st.write(f"å‡¦ç†å¾Œãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {result_df.shape}")
        return result_df
        
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

@st.cache_data
def load_sample_data():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ä»£æ›¿ï¼‰"""
    prefectures = [
        "åŒ—æµ·é“", "é’æ£®çœŒ", "å²©æ‰‹çœŒ", "å®®åŸçœŒ", "ç§‹ç”°çœŒ", "å±±å½¢çœŒ", "ç¦å³¶çœŒ",
        "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ",
        "æ–°æ½ŸçœŒ", "å¯Œå±±çœŒ", "çŸ³å·çœŒ", "ç¦äº•çœŒ", "å±±æ¢¨çœŒ", "é•·é‡çœŒ", "å²é˜œçœŒ",
        "é™å²¡çœŒ", "æ„›çŸ¥çœŒ", "ä¸‰é‡çœŒ", "æ»‹è³€çœŒ", "äº¬éƒ½åºœ", "å¤§é˜ªåºœ", "å…µåº«çœŒ",
        "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±çœŒ", "é³¥å–çœŒ", "å³¶æ ¹çœŒ", "å²¡å±±çœŒ", "åºƒå³¶çœŒ", "å±±å£çœŒ",
        "å¾³å³¶çœŒ", "é¦™å·çœŒ", "æ„›åª›çœŒ", "é«˜çŸ¥çœŒ", "ç¦å²¡çœŒ", "ä½è³€çœŒ", "é•·å´çœŒ",
        "ç†Šæœ¬çœŒ", "å¤§åˆ†çœŒ", "å®®å´çœŒ", "é¹¿å…å³¶çœŒ", "æ²–ç¸„çœŒ"
    ]
    
    years = list(range(2015, 2025))  # 2015-2024å¹´ã®ãƒ‡ãƒ¼ã‚¿
    data = []
    
    # éƒ½é“åºœçœŒã”ã¨ã®åŸºæº–é«˜é½¢åŒ–ç‡ã‚’è¨­å®šï¼ˆ2015å¹´ç¾å®Ÿçš„ãªå€¤ï¼‰
    base_rates = {
        "ç§‹ç”°çœŒ": 33.0, "é«˜çŸ¥çœŒ": 32.5, "å³¶æ ¹çœŒ": 32.0, "å±±å£çœŒ": 31.8,
        "å¾³å³¶çœŒ": 31.5, "å’Œæ­Œå±±çœŒ": 31.2, "é³¥å–çœŒ": 31.0, "æ„›åª›çœŒ": 30.8,
        "å²©æ‰‹çœŒ": 30.5, "å±±å½¢çœŒ": 30.3, "é’æ£®çœŒ": 30.0, "ä½è³€çœŒ": 29.8,
        "é•·å´çœŒ": 29.5, "ç†Šæœ¬çœŒ": 29.3, "å¤§åˆ†çœŒ": 29.0, "å®®å´çœŒ": 28.8,
        "é¹¿å…å³¶çœŒ": 28.5, "åŒ—æµ·é“": 28.2, "ç¦å³¶çœŒ": 28.0, "æ–°æ½ŸçœŒ": 27.8,
        "ç¾¤é¦¬çœŒ": 27.5, "å¯Œå±±çœŒ": 27.3, "çŸ³å·çœŒ": 27.0, "ç¦äº•çœŒ": 26.8,
        "é•·é‡çœŒ": 26.5, "å²é˜œçœŒ": 26.3, "é™å²¡çœŒ": 26.0, "ä¸‰é‡çœŒ": 25.8,
        "æ ƒæœ¨çœŒ": 25.5, "èŒ¨åŸçœŒ": 25.3, "å±±æ¢¨çœŒ": 25.0, "é¦™å·çœŒ": 24.8,
        "åºƒå³¶çœŒ": 24.5, "å²¡å±±çœŒ": 24.3, "äº¬éƒ½åºœ": 24.0, "å…µåº«çœŒ": 23.8,
        "å®®åŸçœŒ": 23.5, "ç¦å²¡çœŒ": 23.3, "æ»‹è³€çœŒ": 23.0, "å¥ˆè‰¯çœŒ": 22.8,
        "å¤§é˜ªåºœ": 22.5, "åƒè‘‰çœŒ": 22.3, "æ„›çŸ¥çœŒ": 22.0, "ç¥å¥ˆå·çœŒ": 21.8,
        "åŸ¼ç‰çœŒ": 21.5, "æ±äº¬éƒ½": 21.0, "æ²–ç¸„çœŒ": 20.0
    }
    
    for pref in prefectures:
        base_rate = base_rates.get(pref, 27.0)
        for year in years:
            # å¹´æ¬¡å¢—åŠ ç‡ï¼ˆç¾å®Ÿçš„ãªé«˜é½¢åŒ–é€²è¡Œã‚’åæ˜ ï¼‰
            year_factor = (year - 2015) * 0.6  # å¹´é–“ç´„0.6%ãšã¤å¢—åŠ 
            # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º
            noise = np.random.normal(0, 0.5)
            rate = base_rate + year_factor + noise
            
            # ç·äººå£ï¼ˆç¾å®Ÿçš„ãªè¦æ¨¡ï¼‰
            if pref == "æ±äº¬éƒ½":
                total_pop = np.random.randint(13000000, 14000000)
            elif pref in ["ç¥å¥ˆå·çœŒ", "å¤§é˜ªåºœ"]:
                total_pop = np.random.randint(8000000, 10000000)
            elif pref in ["æ„›çŸ¥çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ"]:
                total_pop = np.random.randint(5000000, 8000000)
            elif pref in ["åŒ—æµ·é“", "å…µåº«çœŒ", "ç¦å²¡çœŒ"]:
                total_pop = np.random.randint(3000000, 6000000)
            else:
                total_pop = np.random.randint(500000, 3000000)
            
            elderly_pop = int(total_pop * rate / 100)
            
            data.append({
                "éƒ½é“åºœçœŒ": pref,
                "å¹´": year,
                "ç·äººå£": total_pop,
                "65æ­³ä»¥ä¸Šäººå£": elderly_pop,
                "é«˜é½¢åŒ–ç‡": round(rate, 1),
                "åœ°åŸŸ": get_region(pref)
            })
    
    return pd.DataFrame(data)

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
st.sidebar.header("ğŸ”§ åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³")

# ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
data_source = st.sidebar.radio(
    "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ",
    ["Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿"],
    index=0,
    help="å®Ÿéš›ã®æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€æ¤œè¨¼ç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨"
)

df = None

if data_source == "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    st.sidebar.markdown("### ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_files = st.sidebar.file_uploader(
        "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆè¤‡æ•°å¹´å¯¾å¿œï¼‰",
        type=['xls', 'xlsx'],
        accept_multiple_files=True,
        help="ä½æ°‘åŸºæœ¬å°å¸³äººå£ç§»å‹•å ±å‘Šæ›¸ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )
    
    if uploaded_files:
        with st.sidebar:
            st.write("ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­...")
            df = load_uploaded_files(uploaded_files)
    else:
        st.info("ğŸ“‹ æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆä½æ°‘åŸºæœ¬å°å¸³äººå£ç§»å‹•å ±å‘Šæ›¸ï¼‰ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.markdown("""
        **å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«ä¾‹:**
        - 1502stnen.xls (2015å¹´)
        - 1602stnen.xls (2016å¹´)  
        - 2102stnen.xlsx (2021å¹´)
        - 24stnen.xlsx (2024å¹´)
        
        **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:** ç·å‹™çœçµ±è¨ˆå±€ e-Stat
        """)

else:
    st.sidebar.write("ğŸ² ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    df = load_sample_data()

# ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚ŒãŸå ´åˆã®ã¿å‡¦ç†ã‚’ç¶šè¡Œ
if df is not None and not df.empty:
    # å¹´ç¯„å›²é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ã«å¿œã˜ã¦å‹•çš„ã«èª¿æ•´ï¼‰
    available_years = sorted(df["å¹´"].unique())
    year_range = st.sidebar.slider(
        "å¹´ç¯„å›²ã‚’é¸æŠ",
        min_value=min(available_years),
        max_value=max(available_years),
        value=(min(available_years), max(available_years)),
        step=1
    )

    # éƒ½é“åºœçœŒé¸æŠï¼ˆé«˜é½¢åŒ–ç‡é †ã§ã‚½ãƒ¼ãƒˆï¼‰
    selected_prefs = st.sidebar.multiselect(
        "ç‰¹å®šéƒ½é“åºœçœŒã‚’é¸æŠï¼ˆç©ºç™½ã§å…¨ã¦ï¼‰",
        options=sorted(df["éƒ½é“åºœçœŒ"].unique()),
        default=[]
    )

    # åœ°åŸŸé¸æŠï¼ˆåœ°åŸŸåˆ—ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    if "åœ°åŸŸ" in df.columns:
        selected_regions = st.sidebar.multiselect(
            "åœ°åŸŸã‚’é¸æŠï¼ˆç©ºç™½ã§å…¨ã¦ï¼‰",
            options=sorted(df["åœ°åŸŸ"].unique()),
            default=[]
        )
    else:
        selected_regions = []

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered_df = df[
        (df["å¹´"] >= year_range[0]) & 
        (df["å¹´"] <= year_range[1])
    ]

    if selected_prefs:
        filtered_df = filtered_df[filtered_df["éƒ½é“åºœçœŒ"].isin(selected_prefs)]

    if selected_regions and "åœ°åŸŸ" in filtered_df.columns:
        filtered_df = filtered_df[filtered_df["åœ°åŸŸ"].isin(selected_regions)]

    # ãƒ¡ã‚¤ãƒ³åˆ†æ
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(
            "åˆ†æå¯¾è±¡éƒ½é“åºœçœŒæ•°",
            len(filtered_df["éƒ½é“åºœçœŒ"].unique()),
            delta=None
        )

    with col2:
        if len(filtered_df) > 0:
            latest_year_data = filtered_df[filtered_df['å¹´'] == year_range[1]]
            earliest_year_data = filtered_df[filtered_df['å¹´'] == year_range[0]]
            
            if len(latest_year_data) > 0 and len(earliest_year_data) > 0:
                latest_avg = latest_year_data['é«˜é½¢åŒ–ç‡'].mean()
                earliest_avg = earliest_year_data['é«˜é½¢åŒ–ç‡'].mean()
                delta = latest_avg - earliest_avg
                
                st.metric(
                    "å¹³å‡é«˜é½¢åŒ–ç‡ï¼ˆæœ€æ–°å¹´ï¼‰",
                    f"{latest_avg:.1f}%",
                    delta=f"{delta:.1f}%"
                )
            else:
                st.metric("å¹³å‡é«˜é½¢åŒ–ç‡", "ãƒ‡ãƒ¼ã‚¿ãªã—")
        else:
            st.metric("å¹³å‡é«˜é½¢åŒ–ç‡", "ãƒ‡ãƒ¼ã‚¿ãªã—")

    with col3:
        if len(filtered_df) > 0:
            st.metric(
                "ç·ãƒ‡ãƒ¼ã‚¿ä»¶æ•°",
                f"{len(filtered_df):,}ä»¶",
                delta=None
            )

    # å¯è¦–åŒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–")

    # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å¯è¦–åŒ–ã‚’å®Ÿè¡Œ
    if len(filtered_df) > 0:
        # ã‚¿ãƒ–ã§åˆ†æã‚’åˆ†å‰²
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ æ™‚ç³»åˆ—æ¨ç§»", "ğŸ—¾ åœ°åŸŸæ¯”è¼ƒ", "ğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ğŸ” è©³ç´°åˆ†æ"])

        with tab1:
            st.subheader("éƒ½é“åºœçœŒåˆ¥é«˜é½¢åŒ–ç‡ã®æ™‚ç³»åˆ—æ¨ç§»")
            
            # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªç·šã‚°ãƒ©ãƒ•
            fig = px.line(
                filtered_df,
                x="å¹´",
                y="é«˜é½¢åŒ–ç‡",
                color="éƒ½é“åºœçœŒ",
                title="éƒ½é“åºœçœŒåˆ¥é«˜é½¢åŒ–ç‡ã®æ¨ç§»",
                hover_data=["åœ°åŸŸ"] if "åœ°åŸŸ" in filtered_df.columns else None,
                height=600
            )
            
            fig.update_layout(
                xaxis_title="å¹´",
                yaxis_title="é«˜é½¢åŒ–ç‡ (%)",
                hovermode="x unified"
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # åœ°åŸŸåˆ¥å¹³å‡æ¨ç§»ï¼ˆåœ°åŸŸåˆ—ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
            if "åœ°åŸŸ" in filtered_df.columns:
                st.subheader("åœ°åŸŸåˆ¥å¹³å‡é«˜é½¢åŒ–ç‡ã®æ¨ç§»")
                
                region_avg = filtered_df.groupby(["å¹´", "åœ°åŸŸ"])["é«˜é½¢åŒ–ç‡"].mean().reset_index()
                
                fig2 = px.line(
                    region_avg,
                    x="å¹´",
                    y="é«˜é½¢åŒ–ç‡",
                    color="åœ°åŸŸ",
                    title="åœ°åŸŸåˆ¥å¹³å‡é«˜é½¢åŒ–ç‡ã®æ¨ç§»",
                    markers=True,
                    height=500
                )
                
                st.plotly_chart(fig2, use_container_width=True)

        with tab2:
            st.subheader("åœ°åŸŸé–“æ ¼å·®ã®åˆ†æ")
            
            if "åœ°åŸŸ" in filtered_df.columns:
                # ç®±ã²ã’å›³
                fig3 = px.box(
                    filtered_df,
                    x="åœ°åŸŸ",
                    y="é«˜é½¢åŒ–ç‡",
                    title="åœ°åŸŸåˆ¥é«˜é½¢åŒ–ç‡ã®åˆ†å¸ƒ",
                    height=500
                )
                
                fig3.update_xaxes(tickangle=45)
                st.plotly_chart(fig3, use_container_width=True)
                
                # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆå¹´Ã—åœ°åŸŸï¼‰
                st.subheader("å¹´Ã—åœ°åŸŸãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
                
                heatmap_data = filtered_df.groupby(["å¹´", "åœ°åŸŸ"])["é«˜é½¢åŒ–ç‡"].mean().unstack()
                
                fig4 = px.imshow(
                    heatmap_data.T,
                    title="å¹´åˆ¥åœ°åŸŸåˆ¥å¹³å‡é«˜é½¢åŒ–ç‡",
                    color_continuous_scale="YlOrRd",
                    height=400
                )
                
                st.plotly_chart(fig4, use_container_width=True)
            else:
                st.info("åœ°åŸŸæƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã¯åœ°åŸŸåˆ†æãŒå¯èƒ½ã§ã™ã€‚")

        with tab3:
            st.subheader("é«˜é½¢åŒ–ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            
            # æœ€æ–°å¹´ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            latest_year = year_range[1]
            latest_data = filtered_df[filtered_df["å¹´"] == latest_year].sort_values("é«˜é½¢åŒ–ç‡", ascending=False)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**{latest_year}å¹´ é«˜é½¢åŒ–ç‡ä¸Šä½10éƒ½é“åºœçœŒ**")
                if "åœ°åŸŸ" in latest_data.columns:
                    top_10 = latest_data.head(10)[["éƒ½é“åºœçœŒ", "é«˜é½¢åŒ–ç‡", "åœ°åŸŸ"]]
                else:
                    top_10 = latest_data.head(10)[["éƒ½é“åºœçœŒ", "é«˜é½¢åŒ–ç‡"]]
                st.dataframe(top_10.reset_index(drop=True), use_container_width=True)
            
            with col2:
                st.write(f"**{latest_year}å¹´ é«˜é½¢åŒ–ç‡ä¸‹ä½10éƒ½é“åºœçœŒ**")
                if "åœ°åŸŸ" in latest_data.columns:
                    bottom_10 = latest_data.tail(10)[["éƒ½é“åºœçœŒ", "é«˜é½¢åŒ–ç‡", "åœ°åŸŸ"]]
                else:
                    bottom_10 = latest_data.tail(10)[["éƒ½é“åºœçœŒ", "é«˜é½¢åŒ–ç‡"]]
                st.dataframe(bottom_10.reset_index(drop=True), use_container_width=True)
            
            # æ£’ã‚°ãƒ©ãƒ•
            fig5 = px.bar(
                latest_data.head(15),
                x="é«˜é½¢åŒ–ç‡",
                y="éƒ½é“åºœçœŒ",
                color="åœ°åŸŸ" if "åœ°åŸŸ" in latest_data.columns else None,
                title=f"{latest_year}å¹´ é«˜é½¢åŒ–ç‡ä¸Šä½15éƒ½é“åºœçœŒ",
                orientation="h",
                height=600
            )
            
            fig5.update_layout(yaxis={"categoryorder": "total ascending"})
            st.plotly_chart(fig5, use_container_width=True)

        with tab4:
            st.subheader("è©³ç´°çµ±è¨ˆåˆ†æ")
            
            # å¤‰åŒ–ç‡åˆ†æ
            change_analysis = []
            for pref in filtered_df["éƒ½é“åºœçœŒ"].unique():
                pref_data = filtered_df[filtered_df["éƒ½é“åºœçœŒ"] == pref].sort_values("å¹´")
                if len(pref_data) >= 2:
                    start_rate = pref_data.iloc[0]["é«˜é½¢åŒ–ç‡"]
                    end_rate = pref_data.iloc[-1]["é«˜é½¢åŒ–ç‡"]
                    change = end_rate - start_rate
                    change_rate = (change / start_rate) * 100 if start_rate > 0 else 0
                    
                    change_analysis.append({
                        "éƒ½é“åºœçœŒ": pref,
                        "åœ°åŸŸ": pref_data.iloc[0]["åœ°åŸŸ"] if "åœ°åŸŸ" in pref_data.columns else "ä¸æ˜",
                        f"{year_range[0]}å¹´": start_rate,
                        f"{year_range[1]}å¹´": end_rate,
                        "å¢—åŠ ãƒã‚¤ãƒ³ãƒˆ": round(change, 1),
                        "å¢—åŠ ç‡": round(change_rate, 1)
                    })
            
            if change_analysis:  # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å‡¦ç†
                change_df = pd.DataFrame(change_analysis).sort_values("å¢—åŠ ãƒã‚¤ãƒ³ãƒˆ", ascending=False)
                
                st.write("**æœŸé–“ä¸­ã®é«˜é½¢åŒ–ç‡å¤‰åŒ–åˆ†æ**")
                st.dataframe(change_df, use_container_width=True)
                
                # å¤‰åŒ–ç‡ã®å¯è¦–åŒ–
                # sizeãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã¯æ­£ã®å€¤ã®ã¿ä½¿ç”¨ã™ã‚‹ãŸã‚ã€çµ¶å¯¾å€¤ã‚’ä½¿ç”¨
                change_df_for_plot = change_df.copy()
                change_df_for_plot['å¢—åŠ ç‡_çµ¶å¯¾å€¤'] = abs(change_df_for_plot['å¢—åŠ ç‡'])
                
                fig6 = px.scatter(
                    change_df_for_plot,
                    x=f"{year_range[0]}å¹´",
                    y="å¢—åŠ ãƒã‚¤ãƒ³ãƒˆ",
                    color="åœ°åŸŸ" if "åœ°åŸŸ" in change_df_for_plot.columns else None,
                    size="å¢—åŠ ç‡_çµ¶å¯¾å€¤",
                    hover_data=["éƒ½é“åºœçœŒ", "å¢—åŠ ç‡"],
                    title="é«˜é½¢åŒ–ç‡ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³",
                    height=500
                )
                
                st.plotly_chart(fig6, use_container_width=True)
            else:
                st.info("å¤‰åŒ–åˆ†æã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
            
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            st.subheader("çµ±è¨ˆã‚µãƒãƒªãƒ¼")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æœ€é«˜é«˜é½¢åŒ–ç‡", f"{filtered_df['é«˜é½¢åŒ–ç‡'].max():.1f}%")
            
            with col2:
                st.metric("æœ€ä½é«˜é½¢åŒ–ç‡", f"{filtered_df['é«˜é½¢åŒ–ç‡'].min():.1f}%")
            
            with col3:
                st.metric("æ¨™æº–åå·®", f"{filtered_df['é«˜é½¢åŒ–ç‡'].std():.1f}")
            
            with col4:
                st.metric("æ ¼å·®ï¼ˆæœ€å¤§-æœ€å°ï¼‰", f"{filtered_df['é«˜é½¢åŒ–ç‡'].max() - filtered_df['é«˜é½¢åŒ–ç‡'].min():.1f}%")

        # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.header("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

        @st.cache_data
        def convert_df_to_csv(df):
            return df.to_csv(index=False).encode('utf-8')

        csv = convert_df_to_csv(filtered_df)

        st.download_button(
            label="ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f'aging_rate_data_{year_range[0]}_{year_range[1]}.csv',
            mime='text/csv',
        )
    else:
        st.warning("âš ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

else:
    if data_source == "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        st.info("ğŸ‘† ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(f"""
**ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦**: 
- å®Ÿéš›ã®æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿: ç·å‹™çœã€Œä½æ°‘åŸºæœ¬å°å¸³äººå£ç§»å‹•å ±å‘Šæ›¸ã€
- ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: ç¾å®Ÿçš„ãªå‚¾å‘ã‚’åæ˜ ã—ãŸãƒ‡ãƒ¢ç”¨ãƒ‡ãƒ¼ã‚¿

**ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼**: æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆe-Statï¼‰Excelå½¢å¼ (.xls/.xlsx)

**é–‹ç™º**: CUDAç”»åƒåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ  - é«˜é½¢åŒ–ç‡åˆ†ææ‹¡å¼µæ©Ÿèƒ½  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œç‰ˆ
""")
