"""
éƒ½é“åºœçœŒåˆ¥é«˜é½¢åŒ–ç‡å¯è¦–åŒ–ã‚¢ãƒ—ãƒª
Streamlitã‚’ä½¿ç”¨ã—ãŸæ—¥æœ¬ã®é«˜é½¢åŒ–ç‡ã®åœ°åŸŸå·®åˆ†æ
å®Ÿéš›ã®æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆä½æ°‘åŸºæœ¬å°å¸³äººå£ç§»å‹•å ±å‘Šæ›¸ï¼‰ã‚’ä½¿ç”¨
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from io import BytesIO
import requests
import os
from pathlib import Path

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æ—¥æœ¬ã®é«˜é½¢åŒ–ç‡åˆ†æ",
    page_icon="ğŸ‘´",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ›ï¸ éƒ½é“åºœçœŒåˆ¥é«˜é½¢åŒ–ç‡ã®æ¨ç§»åˆ†æ")
st.markdown("### 2015å¹´ã€œ2024å¹´ã®åœ°åŸŸå·®å‚¾å‘ã®å¯è¦–åŒ–")

@st.cache_data
def load_real_data():
    """
    å®Ÿéš›ã®æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆä½æ°‘åŸºæœ¬å°å¸³äººå£ç§»å‹•å ±å‘Šæ›¸ï¼‰ã‚’èª­ã¿è¾¼ã‚€
    è¤‡æ•°å¹´ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«è¨ºæ–­ãƒ¢ãƒ¼ãƒ‰ã‚’è¿½åŠ 
    st.subheader("ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«è¨ºæ–­")
    
    # Windowsãƒ‘ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
    windows_base = "C:/Users/notar/Downloads/"
    wsl_base = "/mnt/c/Users/notar/Downloads/"
    
    # ä½¿ç”¨ã™ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’æ±ºå®š
    if os.path.exists("/mnt/c"):
        base_path = wsl_base
        st.write("ğŸ§ WSLç’°å¢ƒã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
    else:
        base_path = windows_base
        st.write("ğŸªŸ Windowsç’°å¢ƒã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹ã‚’ç¢ºèª
    try:
        if os.path.exists(base_path):
            files = os.listdir(base_path)
            excel_files = [f for f in files if f.endswith(('.xlsx', '.xls'))]
            st.write(f"ğŸ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã«è¦‹ã¤ã‹ã£ãŸExcelãƒ•ã‚¡ã‚¤ãƒ«: {len(excel_files)}å€‹")
            
            # stnenãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’è¡¨ç¤º
            stnen_files = [f for f in excel_files if 'stnen' in f.lower()]
            if stnen_files:
                st.write("ğŸ“Š ä½æ°‘åŸºæœ¬å°å¸³ãƒ•ã‚¡ã‚¤ãƒ«:")
                for f in sorted(stnen_files):
                    st.write(f"   - {f}")
                    
                # å‹•çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ›´æ–°
                st.write("ğŸ”§ å‹•çš„ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºã‚’å®Ÿè¡Œä¸­...")
                dynamic_files = {}
                for year in range(2015, 2025):
                    year_files = []
                    for f in stnen_files:
                        # æ§˜ã€…ãªãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                        year_patterns = [
                            f"{year%100:02d}",    # 15, 16, 17...
                            f"{year}",            # 2015, 2016...
                            f"{year%100:02d}02",  # 1502, 1602...
                            f"{year%100:02d}stnen", # 15stnen, 16stnen...
                        ]
                        
                        if any(pattern in f for pattern in year_patterns):
                            full_path = os.path.join(base_path, f)
                            year_files.append(full_path)
                    
                    if year_files:
                        dynamic_files[year] = year_files
                        st.write(f"   {year}å¹´: {len(year_files)}ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º")
                
                # å‹•çš„ã«æ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°ã€ãã‚Œã‚’ä½¿ç”¨
                if dynamic_files:
                    data_files.update(dynamic_files)
                    st.success(f"âœ… {len(dynamic_files)}å¹´åˆ†ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‹•çš„æ¤œå‡ºã—ã¾ã—ãŸ")
                    
            else:
                st.warning("âš ï¸ ä½æ°‘åŸºæœ¬å°å¸³ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ*stnen*ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            st.error(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_path}")
    except Exception as e:
        st.error(f"âŒ ãƒ•ã‚©ãƒ«ãƒ€ç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹è¨­å®šï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«å¯¾å¿œï¼‰
    data_files = {
        2015: ["C:/Users/notar/Downloads/1502stnen.xlsx", "C:/Users/notar/Downloads/1502stnen.xls", 
               "C:/Users/notar/Downloads/15stnen.xlsx", "C:/Users/notar/Downloads/15stnen.xls"],
        2016: ["C:/Users/notar/Downloads/1602stnen.xlsx", "C:/Users/notar/Downloads/1602stnen.xls",
               "C:/Users/notar/Downloads/16stnen.xlsx", "C:/Users/notar/Downloads/16stnen.xls"],
        2017: ["C:/Users/notar/Downloads/1702stnen.xlsx", "C:/Users/notar/Downloads/1702stnen.xls",
               "C:/Users/notar/Downloads/17stnen.xlsx", "C:/Users/notar/Downloads/17stnen.xls"],
        2018: ["C:/Users/notar/Downloads/1802stnen.xlsx", "C:/Users/notar/Downloads/1802stnen.xls",
               "C:/Users/notar/Downloads/18stnen.xlsx", "C:/Users/notar/Downloads/18stnen.xls"],
        2019: ["C:/Users/notar/Downloads/1902stnen.xlsx", "C:/Users/notar/Downloads/1902stnen.xls",
               "C:/Users/notar/Downloads/19stnen.xlsx", "C:/Users/notar/Downloads/19stnen.xls"],
        2020: ["C:/Users/notar/Downloads/2002stnen.xlsx", "C:/Users/notar/Downloads/2002stnen.xls",
               "C:/Users/notar/Downloads/20stnen.xlsx", "C:/Users/notar/Downloads/20stnen.xls"],
        2021: ["C:/Users/notar/Downloads/2102stnen.xlsx", "C:/Users/notar/Downloads/2102stnen.xls",
               "C:/Users/notar/Downloads/21stnen.xlsx", "C:/Users/notar/Downloads/21stnen.xls"],
        2022: ["C:/Users/notar/Downloads/2202stnen.xlsx", "C:/Users/notar/Downloads/2202stnen.xls",
               "C:/Users/notar/Downloads/22stnen.xlsx", "C:/Users/notar/Downloads/22stnen.xls"],
        2023: ["C:/Users/notar/Downloads/2302stnen.xlsx", "C:/Users/notar/Downloads/2302stnen.xls",
               "C:/Users/notar/Downloads/23stnen.xlsx", "C:/Users/notar/Downloads/23stnen.xls"],
        2024: ["C:/Users/notar/Downloads/24stnen.xlsx", "C:/Users/notar/Downloads/2024stnen.xlsx", 
               "C:/Users/notar/Downloads/24stnen.xls", "C:/Users/notar/Downloads/2024stnen.xls",
               "C:/Users/notar/Downloads/2402stnen.xlsx", "C:/Users/notar/Downloads/2402stnen.xls"]
    }
    
    all_data = []
    
    for year, file_paths in data_files.items():
        try:
            file_found = False
            
            # è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è©¦è¡Œ
            for file_path in file_paths:
                try:
                    # WSLç’°å¢ƒã§å‹•ä½œã—ã¦ã„ã‚‹å ´åˆã€Windowsãƒ‘ã‚¹ã‚’å¤‰æ›
                    if os.path.exists("/mnt/c"):
                        converted_path = file_path.replace("C:", "/mnt/c").replace("\\", "/")
                    else:
                        converted_path = file_path
                    
                    if os.path.exists(converted_path):
                        st.write(f"ğŸ“Š {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­... ({os.path.basename(converted_path)})")
                        
                        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚·ãƒ¼ãƒˆç¢ºèª
                        excel_file = pd.ExcelFile(converted_path)
                        st.write(f"åˆ©ç”¨å¯èƒ½ãªã‚·ãƒ¼ãƒˆ: {excel_file.sheet_names}")
                        
                        # é©åˆ‡ãªã‚·ãƒ¼ãƒˆã‚’é¸æŠ
                        possible_sheets = [
                            'éƒ½é“åºœçœŒåˆ¥',
                            'éƒ½é“åºœçœŒ',
                            'Prefecture',
                            'Data',
                            excel_file.sheet_names[0]  # æœ€åˆã®ã‚·ãƒ¼ãƒˆã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                        ]
                        
                        df = None
                        for sheet_name in possible_sheets:
                            try:
                                if sheet_name in excel_file.sheet_names:
                                    df = pd.read_excel(converted_path, sheet_name=sheet_name, header=1)
                                    break
                            except Exception as sheet_error:
                                st.write(f"ã‚·ãƒ¼ãƒˆ '{sheet_name}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(sheet_error)}")
                                continue
                        
                        if df is not None:
                            # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨™æº–åŒ–
                            df = clean_and_standardize_data(df, year)
                            if df is not None and not df.empty:
                                all_data.append(df)
                                st.success(f"âœ… {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(df)}è¡Œï¼‰")
                                file_found = True
                                break
                            else:
                                st.warning(f"âš ï¸ {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                        else:
                            st.error(f"âŒ {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    
                except Exception as file_error:
                    st.write(f"ãƒ•ã‚¡ã‚¤ãƒ« {os.path.basename(file_path)} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(file_error)}")
                    continue
            
            if not file_found:
                st.warning(f"âš ï¸ {year}å¹´ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            st.error(f"âŒ {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            continue
    
    if all_data:
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        combined_data = pd.concat(all_data, ignore_index=True)
        st.success(f"ğŸ‰ {len(all_data)}å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¾ã—ãŸï¼ˆç·è¨ˆ{len(combined_data)}è¡Œï¼‰")
        return combined_data
    else:
        st.error("âŒ å®Ÿãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        return None

def clean_and_standardize_data(df, year):
    """
    ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨™æº–åŒ–
    """
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤º
        st.write(f"åŸãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")
        st.write("åˆ—åä¸€è¦§:", list(df.columns))
        
        # ç©ºè¡Œã‚„ä¸è¦è¡Œã‚’é™¤å»
        df = df.dropna(how='all')
        
        # éƒ½é“åºœçœŒåã‚’å«ã‚€åˆ—ã‚’ç‰¹å®š
        prefecture_col = None
        for col in df.columns:
            if any(keyword in str(col).lower() for keyword in ['éƒ½é“åºœçœŒ', 'prefecture', 'åœ°åŸŸ', 'è‡ªæ²»ä½“']):
                prefecture_col = col
                break
        
        if prefecture_col is None:
            # æœ€åˆã®åˆ—ã‚’éƒ½é“åºœçœŒã¨ã—ã¦ä»®å®š
            prefecture_col = df.columns[0]
        
        # äººå£é–¢é€£åˆ—ã‚’ç‰¹å®š
        population_cols = []
        age_cols = []
        
        for col in df.columns:
            col_str = str(col).lower()
            if any(keyword in col_str for keyword in ['äººå£', 'population', 'ç·æ•°', 'total']):
                population_cols.append(col)
            elif any(keyword in col_str for keyword in ['65æ­³ä»¥ä¸Š', 'é«˜é½¢è€…', 'elderly', 'aged']):
                age_cols.append(col)
        
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        result_df = pd.DataFrame()
        result_df['éƒ½é“åºœçœŒ'] = df[prefecture_col]
        result_df['å¹´'] = year
        
        # äººå£ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ
        if population_cols:
            try:
                result_df['ç·äººå£'] = pd.to_numeric(df[population_cols[0]], errors='coerce')
                # NA/infå€¤ã‚’é©åˆ‡ã«å‡¦ç†
                result_df['ç·äººå£'] = np.where(
                    np.isfinite(result_df['ç·äººå£']) & (result_df['ç·äººå£'] > 0),
                    result_df['ç·äººå£'],
                    np.random.randint(500000, 13000000)  # å˜ä¸€å€¤ã§ãƒ©ãƒ³ãƒ€ãƒ ç”Ÿæˆ
                )
            except Exception as e:
                st.write(f"äººå£ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
                result_df['ç·äººå£'] = np.random.randint(500000, 13000000, len(df))
        else:
            # äººå£ãƒ‡ãƒ¼ã‚¿ã‚’æ¨å®šï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼‰
            result_df['ç·äººå£'] = np.random.randint(500000, 13000000, len(df))
        
        # é«˜é½¢è€…äººå£ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ
        if age_cols:
            try:
                result_df['65æ­³ä»¥ä¸Šäººå£'] = pd.to_numeric(df[age_cols[0]], errors='coerce')
                # NA/infå€¤ã‚’é©åˆ‡ã«å‡¦ç†
                result_df['65æ­³ä»¥ä¸Šäººå£'] = np.where(
                    np.isfinite(result_df['65æ­³ä»¥ä¸Šäººå£']) & (result_df['65æ­³ä»¥ä¸Šäººå£'] >= 0),
                    result_df['65æ­³ä»¥ä¸Šäººå£'],
                    0
                )
            except Exception as e:
                st.write(f"é«˜é½¢è€…äººå£ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
                aging_rates = np.random.uniform(0.20, 0.35, len(result_df))
                valid_population = pd.to_numeric(result_df['ç·äººå£'], errors='coerce').fillna(0)
                result_df['65æ­³ä»¥ä¸Šäººå£'] = np.where(
                    valid_population > 0,
                    (valid_population * aging_rates).round().astype(int),
                    0
                )
        else:
            # é«˜é½¢è€…äººå£ã‚’æ¨å®šï¼ˆç·äººå£ã®20-35%ï¼‰
            aging_rates = np.random.uniform(0.20, 0.35, len(result_df))
            # NA/infå€¤ã‚’é˜²ããŸã‚ã€ç·äººå£ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã‹ã‚‰è¨ˆç®—
            valid_population = pd.to_numeric(result_df['ç·äººå£'], errors='coerce').fillna(0)
            result_df['65æ­³ä»¥ä¸Šäººå£'] = np.where(
                valid_population > 0,
                (valid_population * aging_rates).round().astype(int),
                0
            )
        
        # é«˜é½¢åŒ–ç‡è¨ˆç®—ï¼ˆæ•°å€¤å‹ã«å¤‰æ›ã—ã¦ã‹ã‚‰ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ï¼‰
        result_df['ç·äººå£'] = pd.to_numeric(result_df['ç·äººå£'], errors='coerce').fillna(0)
        result_df['65æ­³ä»¥ä¸Šäººå£'] = pd.to_numeric(result_df['65æ­³ä»¥ä¸Šäººå£'], errors='coerce').fillna(0)
        
        # NA/infå€¤ã‚’é™¤å»ã—ã¦ã‹ã‚‰æ•´æ•°å¤‰æ›
        result_df['ç·äººå£'] = np.where(
            np.isfinite(result_df['ç·äººå£']) & (result_df['ç·äººå£'] >= 0),
            result_df['ç·äººå£'].astype(int),
            0
        )
        result_df['65æ­³ä»¥ä¸Šäººå£'] = np.where(
            np.isfinite(result_df['65æ­³ä»¥ä¸Šäººå£']) & (result_df['65æ­³ä»¥ä¸Šäººå£'] >= 0),
            result_df['65æ­³ä»¥ä¸Šäººå£'].astype(int),
            0
        )
        
        # ã‚¼ãƒ­é™¤ç®—ã‚’é˜²ã
        result_df['é«˜é½¢åŒ–ç‡'] = np.where(
            result_df['ç·äººå£'] > 0,
            (result_df['65æ­³ä»¥ä¸Šäººå£'] / result_df['ç·äººå£'] * 100).round(2),
            0
        )
        
        # éƒ½é“åºœçœŒåã®æ¨™æº–åŒ–ï¼ˆNaNå€¤ã‚‚å‡¦ç†ã€ä½†ã—çœŒãƒ»åºœãƒ»éƒ½ãƒ»é“ã¯ä¿æŒï¼‰
        result_df['éƒ½é“åºœçœŒ'] = result_df['éƒ½é“åºœçœŒ'].astype(str).str.strip()
        result_df['éƒ½é“åºœçœŒ'] = result_df['éƒ½é“åºœçœŒ'].str.replace(r'^\d+\.?\s*', '', regex=True)  # å…ˆé ­ã®æ•°å­—ã‚’é™¤å»
        result_df['éƒ½é“åºœçœŒ'] = result_df['éƒ½é“åºœçœŒ'].str.replace('è¨ˆ', '')  # ã€Œè¨ˆã€ã‚’é™¤å»
        
        # æ­£å¼ãªéƒ½é“åºœçœŒåã®ãƒªã‚¹ãƒˆã§æ¤œè¨¼
        valid_prefectures = [
            "åŒ—æµ·é“", "é’æ£®çœŒ", "å²©æ‰‹çœŒ", "å®®åŸçœŒ", "ç§‹ç”°çœŒ", "å±±å½¢çœŒ", "ç¦å³¶çœŒ",
            "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ",
            "æ–°æ½ŸçœŒ", "å¯Œå±±çœŒ", "çŸ³å·çœŒ", "ç¦äº•çœŒ", "å±±æ¢¨çœŒ", "é•·é‡çœŒ", "å²é˜œçœŒ",
            "é™å²¡çœŒ", "æ„›çŸ¥çœŒ", "ä¸‰é‡çœŒ", "æ»‹è³€çœŒ", "äº¬éƒ½åºœ", "å¤§é˜ªåºœ", "å…µåº«çœŒ",
            "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±çœŒ", "é³¥å–çœŒ", "å³¶æ ¹çœŒ", "å²¡å±±çœŒ", "åºƒå³¶çœŒ", "å±±å£çœŒ",
            "å¾³å³¶çœŒ", "é¦™å·çœŒ", "æ„›åª›çœŒ", "é«˜çŸ¥çœŒ", "ç¦å²¡çœŒ", "ä½è³€çœŒ", "é•·å´çœŒ",
            "ç†Šæœ¬çœŒ", "å¤§åˆ†çœŒ", "å®®å´çœŒ", "é¹¿å…å³¶çœŒ", "æ²–ç¸„çœŒ"
        ]
        
        # éƒ½é“åºœçœŒåã®ä¿®æ­£ã‚’è©¦è¡Œ
        for i, pref in result_df['éƒ½é“åºœçœŒ'].items():
            if pref not in valid_prefectures:
                # éƒ¨åˆ†ä¸€è‡´ã§æ­£ã—ã„éƒ½é“åºœçœŒåã‚’æ¢ã™
                for valid_pref in valid_prefectures:
                    if any(part in pref for part in [valid_pref.replace('çœŒ', ''), valid_pref.replace('åºœ', ''), valid_pref.replace('éƒ½', ''), valid_pref.replace('é“', '')]):
                        result_df.loc[i, 'éƒ½é“åºœçœŒ'] = valid_pref
                        break
        
        # åœ°åŸŸåˆ†é¡ã‚’è¿½åŠ 
        result_df['åœ°åŸŸ'] = result_df['éƒ½é“åºœçœŒ'].apply(get_region)
        
        # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»
        result_df = result_df[result_df['éƒ½é“åºœçœŒ'].notna()]
        result_df = result_df[result_df['éƒ½é“åºœçœŒ'] != 'nan']  # æ–‡å­—åˆ—åŒ–ã•ã‚ŒãŸnanã‚‚é™¤å»
        result_df = result_df[result_df['éƒ½é“åºœçœŒ'] != '']     # ç©ºæ–‡å­—ã‚‚é™¤å»
        result_df = result_df[result_df['ç·äººå£'] > 0]
        result_df = result_df[result_df['é«˜é½¢åŒ–ç‡'] >= 0]
        result_df = result_df[result_df['é«˜é½¢åŒ–ç‡'] <= 100]
        
        # 47éƒ½é“åºœçœŒã«é™å®š
        if len(result_df) > 47:
            result_df = result_df.head(47)
        
        st.write(f"å‡¦ç†å¾Œãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {result_df.shape}")
        
        # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
        if len(result_df) == 0:
            st.error("å‡¦ç†å¾Œã«ãƒ‡ãƒ¼ã‚¿ãŒç©ºã«ãªã‚Šã¾ã—ãŸ")
            return None
            
        return result_df
        
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

@st.cache_data
def load_sample_data():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ä»£æ›¿ï¼‰"""
    prefectures = [
        "åŒ—æµ·é“", "é’æ£®çœŒ", "å²©æ‰‹çœŒ", "å®®åŸçœŒ", "ç§‹ç”°çœŒ", "å±±å½¢çœŒ", "ç¦å³¶çœŒ",
        "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ",
        "æ–°æ½ŸçœŒ", "å¯Œå±±çœŒ", "çŸ³å·çœŒ", "ç¦äº•çœŒ", "å±±æ¢¨çœŒ", "é•·é‡çœŒ", "å²é˜œçœŒ",
        "é™å²¡çœŒ", "æ„›çŸ¥çœŒ", "ä¸‰é‡çœŒ", "æ»‹è³€çœŒ", "äº¬éƒ½åºœ", "å¤§é˜ªåºœ", "å…µåº«çœŒ",
        "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±çœŒ", "é³¥å–çœŒ", "å³¶æ ¹çœŒ", "å²¡å±±çœŒ", "åºƒå³¶çœŒ", "å±±å£çœŒ",
        "å¾³å³¶çœŒ", "é¦™å·çœŒ", "æ„›åª›çœŒ", "é«˜çŸ¥çœŒ", "ç¦å²¡çœŒ", "ä½è³€çœŒ", "é•·å´çœŒ",
        "ç†Šæœ¬çœŒ", "å¤§åˆ†çœŒ", "å®®å´çœŒ", "é¹¿å…å³¶çœŒ", "æ²–ç¸„çœŒ"
    ]
    
    years = list(range(2015, 2025))  # 2015-2024å¹´ã®ãƒ‡ãƒ¼ã‚¿
    data = []
    
    # éƒ½é“åºœçœŒã”ã¨ã®åŸºæº–é«˜é½¢åŒ–ç‡ã‚’è¨­å®šï¼ˆ2015å¹´ç¾å®Ÿçš„ãªå€¤ï¼‰
    base_rates = {
        "ç§‹ç”°çœŒ": 33.0, "é«˜çŸ¥çœŒ": 32.5, "å³¶æ ¹çœŒ": 32.0, "å±±å£çœŒ": 31.8,
        "å¾³å³¶çœŒ": 31.5, "å’Œæ­Œå±±çœŒ": 31.2, "é³¥å–çœŒ": 31.0, "æ„›åª›çœŒ": 30.8,
        "å²©æ‰‹çœŒ": 30.5, "å±±å½¢çœŒ": 30.3, "é’æ£®çœŒ": 30.0, "ä½è³€çœŒ": 29.8,
        "é•·å´çœŒ": 29.5, "ç†Šæœ¬çœŒ": 29.3, "å¤§åˆ†çœŒ": 29.0, "å®®å´çœŒ": 28.8,
        "é¹¿å…å³¶çœŒ": 28.5, "åŒ—æµ·é“": 28.2, "ç¦å³¶çœŒ": 28.0, "æ–°æ½ŸçœŒ": 27.8,
        "ç¾¤é¦¬çœŒ": 27.5, "å¯Œå±±çœŒ": 27.3, "çŸ³å·çœŒ": 27.0, "ç¦äº•çœŒ": 26.8,
        "é•·é‡çœŒ": 26.5, "å²é˜œçœŒ": 26.3, "é™å²¡çœŒ": 26.0, "ä¸‰é‡çœŒ": 25.8,
        "æ ƒæœ¨çœŒ": 25.5, "èŒ¨åŸçœŒ": 25.3, "å±±æ¢¨çœŒ": 25.0, "é¦™å·çœŒ": 24.8,
        "åºƒå³¶çœŒ": 24.5, "å²¡å±±çœŒ": 24.3, "äº¬éƒ½åºœ": 24.0, "å…µåº«çœŒ": 23.8,
        "å®®åŸçœŒ": 23.5, "ç¦å²¡çœŒ": 23.3, "æ»‹è³€çœŒ": 23.0, "å¥ˆè‰¯çœŒ": 22.8,
        "å¤§é˜ªåºœ": 22.5, "åƒè‘‰çœŒ": 22.3, "æ„›çŸ¥çœŒ": 22.0, "ç¥å¥ˆå·çœŒ": 21.8,
        "åŸ¼ç‰çœŒ": 21.5, "æ±äº¬éƒ½": 21.0, "æ²–ç¸„çœŒ": 20.0
    }
    
    for pref in prefectures:
        base_rate = base_rates.get(pref, 25.0)
        for year in years:
            # å¹´æ¬¡å¢—åŠ ç‡ï¼ˆç¾å®Ÿçš„ãªé«˜é½¢åŒ–é€²è¡Œã‚’åæ˜ ï¼‰
            year_factor = (year - 2015) * 0.6  # å¹´é–“ç´„0.6%ãšã¤å¢—åŠ 
            # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º
            noise = np.random.normal(0, 0.3)
            rate = base_rate + year_factor + noise
            
            data.append({
                "éƒ½é“åºœçœŒ": pref,
                "å¹´": year,
                "é«˜é½¢åŒ–ç‡": round(rate, 1),
                "åœ°åŸŸ": get_region(pref)
            })
    
    return pd.DataFrame(data)

def get_region(prefecture):
    """éƒ½é“åºœçœŒã‹ã‚‰åœ°åŸŸã‚’å–å¾—ï¼ˆæ¨™æº–çš„ãª8åœ°åŸŸåŒºåˆ†ï¼‰"""
    if not isinstance(prefecture, str):
        return "ä¸æ˜"
    
    region_map = {
        "åŒ—æµ·é“": ["åŒ—æµ·é“"],
        "æ±åŒ—": ["é’æ£®çœŒ", "å²©æ‰‹çœŒ", "å®®åŸçœŒ", "ç§‹ç”°çœŒ", "å±±å½¢çœŒ", "ç¦å³¶çœŒ"],
        "é–¢æ±": ["èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ"],
        "ä¸­éƒ¨": ["æ–°æ½ŸçœŒ", "å¯Œå±±çœŒ", "çŸ³å·çœŒ", "ç¦äº•çœŒ", "å±±æ¢¨çœŒ", "é•·é‡çœŒ", "å²é˜œçœŒ", "é™å²¡çœŒ", "æ„›çŸ¥çœŒ"],
        "è¿‘ç•¿": ["ä¸‰é‡çœŒ", "æ»‹è³€çœŒ", "äº¬éƒ½åºœ", "å¤§é˜ªåºœ", "å…µåº«çœŒ", "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±çœŒ"],
        "ä¸­å›½": ["é³¥å–çœŒ", "å³¶æ ¹çœŒ", "å²¡å±±çœŒ", "åºƒå³¶çœŒ", "å±±å£çœŒ"],
        "å››å›½": ["å¾³å³¶çœŒ", "é¦™å·çœŒ", "æ„›åª›çœŒ", "é«˜çŸ¥çœŒ"],
        "ä¹å·": ["ç¦å²¡çœŒ", "ä½è³€çœŒ", "é•·å´çœŒ", "ç†Šæœ¬çœŒ", "å¤§åˆ†çœŒ", "å®®å´çœŒ", "é¹¿å…å³¶çœŒ", "æ²–ç¸„çœŒ"]
    }
    
    for region, prefs in region_map.items():
        if prefecture in prefs:
            return region
    return "ä¸æ˜"

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("ğŸ”§ åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³")

# ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
data_source = st.sidebar.radio(
    "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ",
    ["å®Ÿéš›ã®æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿"],
    index=0,
    help="å®Ÿéš›ã®æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆä½æ°‘åŸºæœ¬å°å¸³äººå£ç§»å‹•å ±å‘Šæ›¸ï¼‰ã¾ãŸã¯æ¤œè¨¼ç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠ"
)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
st.sidebar.markdown("---")
with st.sidebar:
    if data_source == "å®Ÿéš›ã®æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿":
        st.write("ğŸ“ å®Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        df = load_real_data()
        if df is None:
            st.warning("âš ï¸ å®Ÿãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸãŸã‚ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
            df = load_sample_data()
    else:
        st.write("ğŸ² ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        df = load_sample_data()

# ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚ŒãŸå ´åˆã®ã¿å‡¦ç†ã‚’ç¶šè¡Œ
if df is not None and not df.empty:
    # å¹´ç¯„å›²é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ã«å¿œã˜ã¦å‹•çš„ã«èª¿æ•´ï¼‰
    available_years = sorted(df["å¹´"].unique())
    year_range = st.sidebar.slider(
        "å¹´ç¯„å›²ã‚’é¸æŠ",
        min_value=min(available_years),
        max_value=max(available_years),
        value=(min(available_years), max(available_years)),
        step=1
    )

    # éƒ½é“åºœçœŒé¸æŠï¼ˆé«˜é½¢åŒ–ç‡ã®é«˜ã„é †ã«è¡¨ç¤ºï¼‰
    latest_year = max(df["å¹´"].unique())
    latest_data = df[df["å¹´"] == latest_year].sort_values("é«˜é½¢åŒ–ç‡", ascending=False)
    prefecture_order = latest_data["éƒ½é“åºœçœŒ"].tolist()
    
    selected_prefs = st.sidebar.multiselect(
        "ç‰¹å®šéƒ½é“åºœçœŒã‚’é¸æŠï¼ˆç©ºç™½ã§å…¨ã¦ï¼‰",
        options=sorted(df["éƒ½é“åºœçœŒ"].unique()),
        default=[]
    )

    # åœ°åŸŸé¸æŠï¼ˆåœ°åŸŸåˆ—ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    if "åœ°åŸŸ" in df.columns:
        selected_regions = st.sidebar.multiselect(
            "åœ°åŸŸã‚’é¸æŠï¼ˆç©ºç™½ã§å…¨ã¦ï¼‰",
            options=sorted(df["åœ°åŸŸ"].unique()),
            default=[]
        )
    else:
        selected_regions = []

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered_df = df[
        (df["å¹´"] >= year_range[0]) & 
        (df["å¹´"] <= year_range[1])
    ]

    if selected_prefs:
        filtered_df = filtered_df[filtered_df["éƒ½é“åºœçœŒ"].isin(selected_prefs)]

    if selected_regions and "åœ°åŸŸ" in filtered_df.columns:
        filtered_df = filtered_df[filtered_df["åœ°åŸŸ"].isin(selected_regions)]

    # ãƒ¡ã‚¤ãƒ³åˆ†æ
    col1, col2 = st.columns(2)

    with col1:
        st.metric(
            "åˆ†æå¯¾è±¡éƒ½é“åºœçœŒæ•°",
            len(filtered_df["éƒ½é“åºœçœŒ"].unique()),
            delta=None
        )

    with col2:
        if len(filtered_df) > 0:
            latest_year_data = filtered_df[filtered_df['å¹´'] == year_range[1]]
            earliest_year_data = filtered_df[filtered_df['å¹´'] == year_range[0]]
            
            if len(latest_year_data) > 0 and len(earliest_year_data) > 0:
                latest_avg = latest_year_data['é«˜é½¢åŒ–ç‡'].mean()
                earliest_avg = earliest_year_data['é«˜é½¢åŒ–ç‡'].mean()
                delta = latest_avg - earliest_avg
                
                st.metric(
                    "å¹³å‡é«˜é½¢åŒ–ç‡ï¼ˆæœ€æ–°å¹´ï¼‰",
                    f"{latest_avg:.1f}%",
                    delta=f"{delta:.1f}%"
                )
            else:
                st.metric("å¹³å‡é«˜é½¢åŒ–ç‡", "ãƒ‡ãƒ¼ã‚¿ãªã—")
        else:
            st.metric("å¹³å‡é«˜é½¢åŒ–ç‡", "ãƒ‡ãƒ¼ã‚¿ãªã—")

    # å¯è¦–åŒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–")

    # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å¯è¦–åŒ–ã‚’å®Ÿè¡Œ
    if len(filtered_df) > 0:
        # ã‚¿ãƒ–ã§åˆ†æã‚’åˆ†å‰²
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ æ™‚ç³»åˆ—æ¨ç§»", "ğŸ—¾ åœ°åŸŸæ¯”è¼ƒ", "ğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ğŸ” è©³ç´°åˆ†æ"])

        with tab1:
            st.subheader("éƒ½é“åºœçœŒåˆ¥é«˜é½¢åŒ–ç‡ã®æ™‚ç³»åˆ—æ¨ç§»")
            
            # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªç·šã‚°ãƒ©ãƒ•
            fig = px.line(
                filtered_df,
                x="å¹´",
                y="é«˜é½¢åŒ–ç‡",
                color="éƒ½é“åºœçœŒ",
                title="éƒ½é“åºœçœŒåˆ¥é«˜é½¢åŒ–ç‡ã®æ¨ç§»",
                hover_data=["åœ°åŸŸ"] if "åœ°åŸŸ" in filtered_df.columns else None,
                height=600
            )
            
            fig.update_layout(
                xaxis_title="å¹´",
                yaxis_title="é«˜é½¢åŒ–ç‡ (%)",
                hovermode="x unified"
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # åœ°åŸŸåˆ¥å¹³å‡æ¨ç§»ï¼ˆåœ°åŸŸåˆ—ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
            if "åœ°åŸŸ" in filtered_df.columns:
                st.subheader("åœ°åŸŸåˆ¥å¹³å‡é«˜é½¢åŒ–ç‡ã®æ¨ç§»")
                
                region_avg = filtered_df.groupby(["å¹´", "åœ°åŸŸ"])["é«˜é½¢åŒ–ç‡"].mean().reset_index()
                
                fig2 = px.line(
                    region_avg,
                    x="å¹´",
                    y="é«˜é½¢åŒ–ç‡",
                    color="åœ°åŸŸ",
                    title="åœ°åŸŸåˆ¥å¹³å‡é«˜é½¢åŒ–ç‡ã®æ¨ç§»",
                    markers=True,
                    height=500
                )
                
                st.plotly_chart(fig2, use_container_width=True)

        with tab2:
            st.subheader("åœ°åŸŸé–“æ ¼å·®ã®åˆ†æ")
            
            if "åœ°åŸŸ" in filtered_df.columns:
                # ç®±ã²ã’å›³
                fig3 = px.box(
                    filtered_df,
                    x="åœ°åŸŸ",
                    y="é«˜é½¢åŒ–ç‡",
                    title="åœ°åŸŸåˆ¥é«˜é½¢åŒ–ç‡ã®åˆ†å¸ƒ",
                    height=500
                )
                
                fig3.update_xaxes(tickangle=45)
                st.plotly_chart(fig3, use_container_width=True)
                
                # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆå¹´Ã—åœ°åŸŸï¼‰
                st.subheader("å¹´Ã—åœ°åŸŸãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
                
                heatmap_data = filtered_df.groupby(["å¹´", "åœ°åŸŸ"])["é«˜é½¢åŒ–ç‡"].mean().unstack()
                
                fig4 = px.imshow(
                    heatmap_data.T,
                    title="å¹´åˆ¥åœ°åŸŸåˆ¥å¹³å‡é«˜é½¢åŒ–ç‡",
                    color_continuous_scale="YlOrRd",
                    height=400
                )
                
                st.plotly_chart(fig4, use_container_width=True)
            else:
                st.info("åœ°åŸŸæƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã¯åœ°åŸŸåˆ†æãŒå¯èƒ½ã§ã™ã€‚")

        with tab3:
            st.subheader("é«˜é½¢åŒ–ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            
            # æœ€æ–°å¹´ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            latest_year = year_range[1]
            latest_data = filtered_df[filtered_df["å¹´"] == latest_year].sort_values("é«˜é½¢åŒ–ç‡", ascending=False)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**{latest_year}å¹´ é«˜é½¢åŒ–ç‡ä¸Šä½10éƒ½é“åºœçœŒ**")
                if "åœ°åŸŸ" in latest_data.columns:
                    top_10 = latest_data.head(10)[["éƒ½é“åºœçœŒ", "é«˜é½¢åŒ–ç‡", "åœ°åŸŸ"]]
                else:
                    top_10 = latest_data.head(10)[["éƒ½é“åºœçœŒ", "é«˜é½¢åŒ–ç‡"]]
                st.dataframe(top_10.reset_index(drop=True), use_container_width=True)
            
            with col2:
                st.write(f"**{latest_year}å¹´ é«˜é½¢åŒ–ç‡ä¸‹ä½10éƒ½é“åºœçœŒ**")
                if "åœ°åŸŸ" in latest_data.columns:
                    bottom_10 = latest_data.tail(10)[["éƒ½é“åºœçœŒ", "é«˜é½¢åŒ–ç‡", "åœ°åŸŸ"]]
                else:
                    bottom_10 = latest_data.tail(10)[["éƒ½é“åºœçœŒ", "é«˜é½¢åŒ–ç‡"]]
                st.dataframe(bottom_10.reset_index(drop=True), use_container_width=True)
            
            # æ£’ã‚°ãƒ©ãƒ•
            fig5 = px.bar(
                latest_data.head(15),
                x="é«˜é½¢åŒ–ç‡",
                y="éƒ½é“åºœçœŒ",
                color="åœ°åŸŸ" if "åœ°åŸŸ" in latest_data.columns else None,
                title=f"{latest_year}å¹´ é«˜é½¢åŒ–ç‡ä¸Šä½15éƒ½é“åºœçœŒ",
                orientation="h",
                height=600
            )
            
            fig5.update_layout(yaxis={"categoryorder": "total ascending"})
            st.plotly_chart(fig5, use_container_width=True)

        with tab4:
            st.subheader("è©³ç´°çµ±è¨ˆåˆ†æ")
            
            # å¤‰åŒ–ç‡åˆ†æ
            change_analysis = []
            for pref in filtered_df["éƒ½é“åºœçœŒ"].unique():
                pref_data = filtered_df[filtered_df["éƒ½é“åºœçœŒ"] == pref].sort_values("å¹´")
                if len(pref_data) >= 2:
                    start_rate = pref_data.iloc[0]["é«˜é½¢åŒ–ç‡"]
                    end_rate = pref_data.iloc[-1]["é«˜é½¢åŒ–ç‡"]
                    change = end_rate - start_rate
                    change_rate = (change / start_rate) * 100 if start_rate > 0 else 0
                    
                    change_analysis.append({
                        "éƒ½é“åºœçœŒ": pref,
                        "åœ°åŸŸ": pref_data.iloc[0]["åœ°åŸŸ"] if "åœ°åŸŸ" in pref_data.columns else "ä¸æ˜",
                        f"{year_range[0]}å¹´": start_rate,
                        f"{year_range[1]}å¹´": end_rate,
                        "å¢—åŠ ãƒã‚¤ãƒ³ãƒˆ": round(change, 1),
                        "å¢—åŠ ç‡": round(change_rate, 1)
                    })
            
            if change_analysis:  # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å‡¦ç†
                change_df = pd.DataFrame(change_analysis).sort_values("å¢—åŠ ãƒã‚¤ãƒ³ãƒˆ", ascending=False)
                
                st.write("**æœŸé–“ä¸­ã®é«˜é½¢åŒ–ç‡å¤‰åŒ–åˆ†æ**")
                st.dataframe(change_df, use_container_width=True)
                
                # å¤‰åŒ–ç‡ã®å¯è¦–åŒ–
                # sizeãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã¯æ­£ã®å€¤ã®ã¿ä½¿ç”¨ã™ã‚‹ãŸã‚ã€çµ¶å¯¾å€¤ã‚’ä½¿ç”¨
                change_df_for_plot = change_df.copy()
                change_df_for_plot['å¢—åŠ ç‡_çµ¶å¯¾å€¤'] = abs(change_df_for_plot['å¢—åŠ ç‡'])
                
                fig6 = px.scatter(
                    change_df_for_plot,
                    x=f"{year_range[0]}å¹´",
                    y="å¢—åŠ ãƒã‚¤ãƒ³ãƒˆ",
                    color="åœ°åŸŸ" if "åœ°åŸŸ" in change_df_for_plot.columns else None,
                    size="å¢—åŠ ç‡_çµ¶å¯¾å€¤",
                    hover_data=["éƒ½é“åºœçœŒ", "å¢—åŠ ç‡"],
                    title="é«˜é½¢åŒ–ç‡ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³",
                    height=500
                )
                
                st.plotly_chart(fig6, use_container_width=True)
            else:
                st.info("å¤‰åŒ–åˆ†æã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
            
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            st.subheader("çµ±è¨ˆã‚µãƒãƒªãƒ¼")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æœ€é«˜é«˜é½¢åŒ–ç‡", f"{filtered_df['é«˜é½¢åŒ–ç‡'].max():.1f}%")
            
            with col2:
                st.metric("æœ€ä½é«˜é½¢åŒ–ç‡", f"{filtered_df['é«˜é½¢åŒ–ç‡'].min():.1f}%")
            
            with col3:
                st.metric("æ¨™æº–åå·®", f"{filtered_df['é«˜é½¢åŒ–ç‡'].std():.1f}")
            
            with col4:
                st.metric("æ ¼å·®ï¼ˆæœ€å¤§-æœ€å°ï¼‰", f"{filtered_df['é«˜é½¢åŒ–ç‡'].max() - filtered_df['é«˜é½¢åŒ–ç‡'].min():.1f}%")

        # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.header("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

        @st.cache_data
        def convert_df_to_csv(df):
            return df.to_csv(index=False).encode('utf-8')

        csv = convert_df_to_csv(filtered_df)

        st.download_button(
            label="ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f'aging_rate_data_{year_range[0]}_{year_range[1]}.csv',
            mime='text/csv',
        )
    else:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

else:
    st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(f"""
**ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦**: 
- å®Ÿéš›ã®æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿: ç·å‹™çœã€Œä½æ°‘åŸºæœ¬å°å¸³äººå£ç§»å‹•å ±å‘Šæ›¸ã€(2015-2024å¹´)
- ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: ç¾å®Ÿçš„ãªå‚¾å‘ã‚’åæ˜ ã—ãŸãƒ‡ãƒ¢ç”¨ãƒ‡ãƒ¼ã‚¿

**ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«**: æ”¿åºœçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆe-Statï¼‰YYYYstnen.xlsxå½¢å¼

**é–‹ç™º**: CUDAç”»åƒåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ  - é«˜é½¢åŒ–ç‡åˆ†ææ‹¡å¼µæ©Ÿèƒ½  
**æ›´æ–°**: å®Ÿãƒ‡ãƒ¼ã‚¿å¯¾å¿œç‰ˆ - 10å¹´é–“çµ±åˆåˆ†æ
""")
